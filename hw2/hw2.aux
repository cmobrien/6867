\relax 
\@writefile{toc}{\contentsline {section}{Support Vector Machine}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The separator and margin computed by our SVM implementation using a small example.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Applications}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The separators computed by our SVM implementation on a variety of different data sets with $C = 1$.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The resulting linear separator when the data is not linearly separable.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The parameters which minimized validation error rates for both the linear kernel and the Gaussian kernel on each data set. The number of support vectors resulting from these parameters and the test error rate are also shown.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Kernels}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The resulting separators when using the Gaussian kernel (with the optimal parameters shown in Figure 4).\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Analyzing C}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The effects of $C$ on the separator for \texttt  {stdev1}, shown on the training data. Support vectors are shown as dots, all other points as plusses. We can see that the smaller $C$ leads to a much wider margin and more support vectors.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces TEST\relax }}{\thepage }}
\@writefile{toc}{\contentsline {section}{Logistic Regression}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Theory}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Experiment}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The resulting separator on \texttt  {nonSep}, with $\lambda = 0$.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The resulting separator on \texttt  {stdev2} Training Data.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The separators computed by our logistic regression implementation on a variety of different data sets with $\lambda = 0$.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {section}{Multi-Class Classification}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Support Vector Machines}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The impact of $\lambda $ on support vectors. Support vectors are shown as dots, and all other points as plusses.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Validation Error for various values of $C$\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Logistic Regression}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Discussion}{\thepage }}
