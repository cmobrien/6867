\relax 
\@writefile{toc}{\contentsline {section}{Introduction}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Data}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Each subfigure shows the distribution over some personal information about the students in our data set. We can see that students are primarily sophomore males in course $6$, and most receive an $A$ or $B$ in the class.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Features}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Roadmap}{\thepage }}
\@writefile{toc}{\contentsline {section}{Regression}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Implementation}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Results}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The left column shows the value of the MSE, while the right column shows the number of errors in the test set. The top row shows these values as a function of the number of assignments included as features, and the bottom rows shows the values as a function of percentage of the final grade included as features. All plots show results for both when we were minimizing MSE and when we were minimizing number of errors.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Each column represents the weights returned by ridge regression with the optimal value of $\lambda $, using the number of assignments specified in the column head as features. \relax }}{\thepage }}
\@writefile{toc}{\contentsline {section}{Ordered Logit/Probit}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Ordered Probit}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The CDF and PDF of Gaussian and logistic distributions with mean $0$ and standard deviation $1$.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Ordered Logit}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The distribution over differences between final grades and predicted grades. Each curve corresponds to a different number of assignments used as features to compute the predicted grades.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Choosing a Model}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Applying To Our Data}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Depicts the test error as we increase the number of assignments that we include as features. Each graph shows the results using each of the ordered logit and ordered probit models.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{Feature Weights}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Each column represents the weights returned by ordered probit with the optimal value of $\lambda $, using the number of assignments specified in the column head as features.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{Grade Distributions}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Depicts the value of the minimum negative log likelihood as we increase the number of assignments used as features. Each graph shows the results using each of the ordered logit and ordered probit models.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The probability distributions predicted by ordered probit for students described in \textit  {Understanding the Distributions} section.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{Understanding the Distributions}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Visualizations of the maximum likelihood values when finding distributions using ordered probit. The left column shows a histogram of students who had a maximum likelihood value (bucketed to 5\%), for both students we could classify correctly and those we couldn't. The right column shows the ratio of the maximum likelihood value to the percentage of students with that value that we could guess correctly. The dotted line show the average, which we want to be close to 1.\relax }}{\thepage }}
\@writefile{toc}{\contentsline {section}{Fixed Cutoff Gaussian Probability}{\thepage }}
\@writefile{toc}{\contentsline {section}{Estimation}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Visualizations of the maximum likelihood values when finding distributions using FCGPE. The left column shows a histogram of students who had a maximum likelihood value (bucketed to 5\%), for both students we could classify correctly and those we couldn't. The right column shows the ratio of the maximum likelihood value to the percentage of students with that value that we could guess correctly. The dotted line show the average, which we want to be close to 1.\relax }}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Depicts the value of the minimum negative log likelihood as we increase the number of assignments that we include as features. Each graph shows the results using FCGEP and probit (replicated from Figure 10 for comparison).\relax }}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{Implementation}{\thepage }}
\@writefile{toc}{\contentsline {section}{Results}{\thepage }}
\@writefile{toc}{\contentsline {section}{Discussion}{\thepage }}
